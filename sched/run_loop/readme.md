# RunLoop

## Пререквизиты

- [fiber/yield](/tasks/fiber/yield)

---

В задаче [sched/thread_pool](/tasks/sched/thread_pool) мы написали пул потоков для исполнения задач.

Затем в задаче [fiber/yield](/tasks/fiber/yield) мы использовали пул потоков как планировщик для кооперативных файберов.

Если теперь мы посмотрим на нашу реализацию файберов, то обнаружим, что зависимость от пула как планировщика в ней сводится к очень простой гарантии: 

_запланированная (в пул) служебная задача однажды будет исполнена (в одном из потоков пула)_. 

Воспользуемся этим наблюдением и абстрагируем планировщик задач: 

## `IScheduler`

_Планировщик задач_ (_task scheduler_) – это сервис, планирующий задачи на исполнение (в некотором _execution context_).
 
Планировщик реализует интерфейс [`sched::task::IScheduler`](exe/sched/task/scheduler.hpp) с единственным методом `Submit` – запланировать задачу на исполнение.

**Единственная гарантия**, которую планировщик дает своему пользователю: _запланированная задача будет исполнена_.

В каком потоке и когда именно – зависит от конкретной реализации планировщика, которая скрыта от пользователя за интерфейсом.

### `Submit`

Договоримся, что пользователь, который хочет запланировать лямбду, не будет вызывать метод `Submit` на планировщике напрямую. 

Вместо этого он будет использовать свободную функцию `sched::task::Submit`:

```cpp
// Пул потоков реализует sched::task::IScheduler
sched::ThreadPool pool{4};
pool.Start();

sched::task::Submit(pool, [] {
  fmt::println("Running on thread pool");
});

pool.Stop();
```

См. [интрузивные задачи](/tasks/sched/intrusive).

### Файберы

Теперь планировщик файберов – не конкретный `sched::ThreadPool`, а абстрактный `sched::task::IScheduler`.

## `RunLoop`

Добавим в `exe` еще один планировщик задач – `RunLoop`:

```cpp
void RunLoopExample() {
  using namespace exe;
  
  // Очередь задач
  sched::RunLoop loop;
  
  // Добавим задачу в очередь
  sched::task::Submit(loop, [] {
    fmt::println("1st");
  });
  
  // И еще одну
  sched::task::Submit(loop, [] {
    fmt::println("2nd");
  });

  // <-- Теперь обе задачи находятся в очереди RunLoop,
  // пока ни одна из них не была запущена

  // Запустим первую задачу
  loop.RunNext();

  // Запланируем третью задачу
  sched::task::Submit(loop, [] {
    fmt::println("3rd");
  });

  // "Опустошаем" очередь задач, т.е.
  // исполняем задачи до тех пор, пока очередь не опустеет
  size_t tasks = loop.Run();
  // <-- Выполнены все три задачи
  assert(tasks == 2);
}
```

[`RunLoop`](exe/sched/run_loop.hpp) – это всего лишь очередь задач.

`Submit` добавляет задачу в конец этой очереди.

Задачи, запланированные в `RunLoop`, запускаются **вручную** с помощью методов `RunNext`, `RunAtMost` и `Run`, которые "крутят цикл".

Собственных потоков у `RunLoop` нет.

С `RunLoop` должен работать только один поток.

### Файберы

Запустим в `RunLoop` наши файберы:

```cpp
void FiberLoop() {
  using namespace exe;
  
  // Планировщик для файберов
  sched::RunLoop loop;

  for (size_t i = 1; i <= 3; ++i) {
    fiber::Go(loop, [i] {
      fmt::println("Fiber #{} started", i);

      for (size_t j = 0; j < 7; ++j) {
        fiber::Yield();

        fmt::println("Fiber #{}, iter = {}", i, j);
      }
    });
  }

  // Детерминированное исполнение:
  
  loop.RunAtMost(3);  // Делаем по шагу каждым файбером
  
  loop.Run();
}
```

### Тесты

Теперь с помощью `RunLoop` мы можем писать детерминированные юнит-тесты для файберов!

В задаче [fiber/mutex](/tasks/fiber/mutex) с помощью вашего `RunLoop` будут тестироваться примитивы синхронизации, которые вы напишите для файберов: `Event`, `Mutex`, `WaitGroup`.


## Дизайн

Абстракция планировщика делит [наш фреймворк] concurrency на два ортогональных измерения:

- С помощью _выразительных средств_ (пока это _файберы_) разработчик описывает цепочки (графы) _задач_
- _Среда исполнения_ _исполняет_ эти цепочки

Декомпозиция позволит нам развивать эти измерения **независимо**: дальше мы будем

- вводить новые средства выразительности (_futures_, _stackless coroutines_) для описания конкурентных активностей,
- оптимизировать реализацию планировщика (_work-stealing thread pool_).

Кроме того, мы можем добавлять новые типы планировщиков: таймеры, IO.